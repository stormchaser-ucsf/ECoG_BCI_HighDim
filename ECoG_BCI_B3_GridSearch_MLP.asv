%% LOOKING AT REPRESENTATIONAL DRIFT
% is there a difference between any two days recordings

clc;clear
root_path = 'F:\DATA\ecog data\ECoG BCI\GangulyServer\Multistate B3';
addpath(genpath('C:\Users\nikic\Documents\GitHub\ECoG_BCI_HighDim'))
cd(root_path)
addpath('C:\Users\nikic\Documents\MATLAB\DrosteEffect-BrewerMap-5b84f95')
load session_data_B3
addpath 'C:\Users\nikic\Documents\MATLAB'
pooling=0;
condn_data_day={};
for i=1:11%length(session_data)
    condn_data={};
    folders_imag =  strcmp(session_data(i).folder_type,'I');
    folders_online = strcmp(session_data(i).folder_type,'O');
    folders_batch = strcmp(session_data(i).folder_type,'B');

    imag_idx = find(folders_imag==1);
    online_idx = find(folders_online==1);
    batch_idx = find(folders_batch==1);


    %%%%%% load imagined data
    folders = session_data(i).folders(imag_idx);
    day_date = session_data(i).Day;
    files=[];
    for ii=1:length(folders)
        folderpath = fullfile(root_path, day_date,'Robot3DArrow',folders{ii},'Imagined');
        %cd(folderpath)
        files = [files;findfiles('',folderpath)'];
    end
    load('ECOG_Grid_8596_000067_B3.mat')
    %condn_data = [condn_data;load_data_for_MLP_TrialLevel_B3(files,ecog_grid,0,pooling)];
    tmp= load_data_for_MLP_TrialLevel_B3(files,ecog_grid,0,pooling);

    % z-scoring    
    %x=[tmp(1:end).neural];
    %s = std(x',1)';
    %x = mean(x,2);    
    %for j =1:length(tmp)
        %tmp(j).neural =  (tmp(j).neural -x)./s;
        %tmp(j).neural =  (tmp(j).neural -mean(tmp(j).neural,2));
    %end

    for j=1:length(tmp)
        tmp(j).targetID=i;
    end
    condn_data_day{i}=tmp;
end

% make them all into one giant struct
tmp=cell2mat(condn_data_day(1));
condn_data_overall=tmp;
for i=2:length(condn_data_day)
    tmp=cell2mat(condn_data_day(i));
    for k=1:length(tmp)
        condn_data_overall(end+1) =tmp(k);
    end
end

conf_matrix_overall=[];num_test_trials=[];
for iter=1:10

    % paritioning the dataset
    num_classes = length(unique([condn_data_overall.targetID]));
    test_idx = randperm(length(condn_data_overall),round(0.15*length(condn_data_overall)));
    test_idx=test_idx(:);
    I = ones(length(condn_data_overall),1);
    I(test_idx)=0;
    train_val_idx = find(I~=0);
    prop = (0.7/0.85);
    tmp_idx = randperm(length(train_val_idx),round(prop*length(train_val_idx)));
    train_idx = train_val_idx(tmp_idx);train_idx=train_idx(:);
    I = ones(length(condn_data_overall),1);
    I([train_idx;test_idx])=0;
    val_idx = find(I~=0);val_idx=val_idx(:);

    % training options for NN
    [options,XTrain,YTrain] = ...
        get_options(condn_data_overall,val_idx,train_idx);

    % design the neural net
    aa=condn_data_overall(1).neural;
    s=size(aa,1);
    layers = get_layers2(64,64,s,num_classes);

    % train the network
    net = trainNetwork(XTrain,YTrain,layers,options);

    % test performance on held out trials, bin level accuracy
    [cv_perf,conf_matrix] = test_network(net,condn_data_overall,test_idx,num_classes);
    conf_matrix;


    % test performance on held out trials, trial level accuracy
    conf_matrix_trialLevel = ...
        test_network_trialLevel(net,condn_data_overall,test_idx,num_classes);

    conf_matrix_overall(iter,:,:) = conf_matrix_trialLevel;
    num_test_trials(iter) = length(test_idx);

end

clear condn_data_overall
save day_of_recording_analyses_B3 -v7.3

tmp = squeeze(nanmean(conf_matrix_overall,1));
%tmp=squeeze(nanmean(conf_matrix,1));
figure;imagesc(tmp*100)
colormap(brewermap(128,'Blues'))
clim([0 100])
set(gcf,'color','w')
% add text
for j=1:size(tmp,1)
    for k=1:size(tmp,2)
        if j==k
            text(j-0.35,k,num2str(round(100*tmp(k,j),2)),'Color','w')
        else
            text(j-0.35,k,num2str(round(100*tmp(k,j),2)),'Color','k')
        end
    end
end
box on
xticks(1:11)
yticks(1:11)
xticklabels(1:11)
yticklabels(1:11)
xlabel('Predicted Days')
ylabel('True Days')
title(['Accuracy of ' num2str(100*mean(diag(tmp))) '%'])

% bino pdf for pvalue
n = median(num_test_trials);
p = mean(diag(tmp));
succ = floor(n*p);
%succ = mean(diag(tmp));
%p = succ/n;
xx = 0:n;
bp = binopdf(xx,n,p);
figure;plot(xx,bp)
ch = ceil((1/10)*n);
vline(ch)
[aa,bb] = find(xx==ch);
title(num2str(sum(bp(1:bb))))

pval = binopdf(succ,n,1/10);

%% LOOKING AT THE IMPORTANCE OF DIFFERENT FEATURES (MAIN)
% code here is to look at trial level decoding accuracies with respect to
% all three features, each individual feature alone, and combination of
% features -> delta+hg, delta+beta, beta+hg

% get the data in trial format
tic

clc;clear;
root_path = 'F:\DATA\ecog data\ECoG BCI\GangulyServer\Multistate B3';
addpath(genpath('C:\Users\nikic\Documents\GitHub\ECoG_BCI_HighDim'))
cd(root_path)
addpath('C:\Users\nikic\Documents\MATLAB\DrosteEffect-BrewerMap-5b84f95')
load session_data_B3
addpath 'C:\Users\nikic\Documents\MATLAB'
pooling=0;
condn_data={};
for i=1:11%length(session_data)
    folders_imag =  strcmp(session_data(i).folder_type,'I');
    folders_online = strcmp(session_data(i).folder_type,'O');
    folders_batch = strcmp(session_data(i).folder_type,'B');

    imag_idx = find(folders_imag==1);
    online_idx = find(folders_online==1);
    batch_idx = find(folders_batch==1);


    %%%%%% load imagined data
    folders = session_data(i).folders(imag_idx);
    day_date = session_data(i).Day;
    files=[];
    for ii=1:length(folders)
        folderpath = fullfile(root_path, day_date,'Robot3DArrow',folders{ii},'Imagined');
        %cd(folderpath)
        files = [files;findfiles('',folderpath)'];
    end
    load('ECOG_Grid_8596_000067_B3.mat')
    condn_data = [condn_data;load_data_for_MLP_TrialLevel_B3(files,ecog_grid,0,pooling)];

    %%%%%% load online data
    folders = session_data(i).folders(online_idx);
    day_date = session_data(i).Day;
    files=[];
    for ii=1:length(folders)
        folderpath = fullfile(root_path, day_date,'Robot3DArrow',folders{ii},'BCI_Fixed');
        %cd(folderpath)
        files = [files;findfiles('',folderpath)'];
    end
    condn_data = [condn_data;load_data_for_MLP_TrialLevel_B3(files,ecog_grid,1,pooling) ];

    %%%%%% load batch data
    folders = session_data(i).folders(batch_idx);
    day_date = session_data(i).Day;
    files=[];
    for ii=1:length(folders)
        folderpath = fullfile(root_path, day_date,'Robot3DArrow',folders{ii},'BCI_Fixed');
        %cd(folderpath)
        files = [files;findfiles('',folderpath)'];
    end
    condn_data = [condn_data;load_data_for_MLP_TrialLevel_B3(files,ecog_grid,2,pooling) ];
end

% make them all into one giant struct
tmp=cell2mat(condn_data(1));
condn_data_overall=tmp;
for i=2:length(condn_data)
    tmp=cell2mat(condn_data(i));
    for k=1:length(tmp)
        condn_data_overall(end+1) =tmp(k);
    end
end


% different feeature combinations
feat_idx{1}=[1:759];% all features
feat_idx{2}=[507:759]; % only hG
feat_idx{3}=[1:253]; % only delta
feat_idx{4}=[254:506]; % only beta
feat_idx{5}=[1:253 254:506]; % delta and beta
feat_idx{6}=[1:253 507:759]; % delta and hg
feat_idx{7}=[254:506 507:759]; % hg and beta

feat_type = {'all','hG','delta','beta','delta and beta','delta and hG','hG and beta'};

condn_data_overall_bkup=condn_data_overall;
acc_overall={};
for i=1:length(feat_idx)

    condn_data_overall={};k=1;
    feat =  feat_idx{i};
    for j=1:length(condn_data_overall_bkup)
        tmp = condn_data_overall_bkup(j).neural;
        tid = condn_data_overall_bkup(j).targetID;
        t_type = condn_data_overall_bkup(j).trial_type;
        if ~isempty(tmp)
            tmp = tmp(feat,:);
            condn_data_overall(k).neural = tmp;
            condn_data_overall(k).targetID = tid;
            condn_data_overall(k).trial_type = t_type;
            k=k+1;
        end
    end

    cv_perf=[];
    for iter=1:15

        % split into training and testing trials, 15% test, 15% val, 70% test
        xx=1;xx1=1;xx2=1;yy=0;
        while xx<7 || xx1<7 || xx2<7
            prop = 0.15;
            test_idx = randperm(length(condn_data_overall),round(prop*length(condn_data_overall)));
            test_idx=test_idx(:);
            I = ones(length(condn_data_overall),1);
            I(test_idx)=0;
            train_val_idx = find(I~=0);
            prop1 = (0.7/(1-prop));
            tmp_idx = randperm(length(train_val_idx),round(prop1*length(train_val_idx)));
            train_idx = train_val_idx(tmp_idx);train_idx=train_idx(:);
            I = ones(length(condn_data_overall),1);
            I([train_idx;test_idx])=0;
            val_idx = find(I~=0);val_idx=val_idx(:);
            xx = length(unique([condn_data_overall(train_idx).targetID]));
            xx1 = length(unique([condn_data_overall(val_idx).targetID]));
            xx2 = length(unique([condn_data_overall(test_idx).targetID]));
            yy=yy+1;
        end
       

        % training options for NN
        [options,XTrain,YTrain] = ...
            get_options(condn_data_overall,val_idx,train_idx);


        %layers = get_layers2(128,128,size(condn_data_overall(1).neural,1));
        layers = get_layers1(120,size(condn_data_overall(1).neural,1));
        net = trainNetwork(XTrain,YTrain,layers,options);
        %[cv_perf,conf_matrix] = test_network(net,condn_data_overall,test_idx);
        [conf_matrix] = test_network_trialLevel(net,condn_data_overall,test_idx);
        cv_perf(iter) = mean(diag(conf_matrix));
    end
    acc_overall(i).acc = [cv_perf]; % if adding in more iterations
    acc_overall(i).feat_type = feat_type{i};

end

save Feature_Importance_Decoding_B3 acc_overall -v7.3
toc


% plotting
tmp=[];
for i=1:length(acc_overall)
    tmp = [tmp acc_overall(i).acc'];
end
figure;
idx = [1 6 7 5 2 3 4];
boxplot(tmp(:,idx),'Whisker',3)
xticks(1:size(tmp,2))
xticklabels(feat_type(idx))
ylim([0.45 1])
hline(1/7,'--r')
xlabel('Neural Feature')
ylabel('Offline Cross. Val Decoding Acc')
yticks([0:.1:1])
set(gcf,'Color','w')
box off
set(gca,'LineWidth',1)
a = get(get(gca,'children'),'children');   
for i=15:21%length(a)
    a(i).Color='k';    
end

% running the binomial tests for significance 
% the num of trials is 261
tmp=tmp(:,idx);
pval=[];
for i=1:size(tmp,2)
    xx = tmp(:,i);
    n = length(test_idx);    
    p = mean(xx);
    xx= 0:n;
    bp = binopdf(xx,n,p);
    ch = ceil((1/7)*n);
    [aa,bb] = find(xx==ch);
    pval(i) = sum(bp(1:bb));
end
 


%% MAIN
% code to grid search to best get MLP parameters
% trying here for layer width and number of units

% DUE TO NOISE IN DEC, BAD CHANNELS ARE  bad_ch = [14,15,21,22,]

% get the data in trial format
clc;clear
root_path = 'F:\DATA\ecog data\ECoG BCI\GangulyServer\Multistate B3';
addpath(genpath('C:\Users\nikic\Documents\GitHub\ECoG_BCI_HighDim'))
cd(root_path)
addpath('C:\Users\nikic\Documents\MATLAB\DrosteEffect-BrewerMap-5b84f95')
load session_data_B3
addpath 'C:\Users\nikic\Documents\MATLAB'
condn_data={};
pooling=0;
for i=1:11%length(session_data)
    folders_imag =  strcmp(session_data(i).folder_type,'I');
    folders_online = strcmp(session_data(i).folder_type,'O');
    folders_batch = strcmp(session_data(i).folder_type,'B');

    imag_idx = find(folders_imag==1);
    online_idx = find(folders_online==1);
    batch_idx = find(folders_batch==1);


    %%%%%% load imagined data
    folders = session_data(i).folders(imag_idx);
    day_date = session_data(i).Day;
    files=[];
    for ii=1:length(folders)
        folderpath = fullfile(root_path, day_date,'Robot3DArrow',folders{ii},'Imagined');
        %cd(folderpath)
        files = [files;findfiles('',folderpath)'];
    end
    load('ECOG_Grid_8596_000067_B3.mat')
    condn_data = [condn_data;load_data_for_MLP_TrialLevel_B3(files,ecog_grid,0,pooling)];

    %%%%%% load online data
    folders = session_data(i).folders(online_idx);
    day_date = session_data(i).Day;
    files=[];
    for ii=1:length(folders)
        folderpath = fullfile(root_path, day_date,'Robot3DArrow',folders{ii},'BCI_Fixed');
        %cd(folderpath)
        files = [files;findfiles('',folderpath)'];
    end
    condn_data = [condn_data;load_data_for_MLP_TrialLevel_B3(files,ecog_grid,1,pooling) ];

    %%%%%% load batch data
    folders = session_data(i).folders(batch_idx);
    day_date = session_data(i).Day;
    files=[];
    for ii=1:length(folders)
        folderpath = fullfile(root_path, day_date,'Robot3DArrow',folders{ii},'BCI_Fixed');
        %cd(folderpath)
        files = [files;findfiles('',folderpath)'];
    end
    condn_data = [condn_data;load_data_for_MLP_TrialLevel_B3(files,ecog_grid,2,pooling) ];
end

% make them all into one giant struct
tmp=cell2mat(condn_data(1));
condn_data_overall=tmp;
for i=2:length(condn_data)
    tmp=cell2mat(condn_data(i));
    for k=1:length(tmp)
        condn_data_overall(end+1) =tmp(k);
    end
end

condn_data_overall1={};kk=1;
for ii=1:length(condn_data_overall)   
    if ~isempty(condn_data_overall(ii).neural)
        condn_data_overall1(kk).neural = condn_data_overall(ii).neural;
        condn_data_overall1(kk).targetID = condn_data_overall(ii).targetID;
        condn_data_overall1(kk).trial_type = condn_data_overall(ii).trial_type;
        kk=kk+1;
    end
end
condn_data_overall = condn_data_overall1;

%cv_acc_overall={};
%cv_acc2_overall={};
%cv_acc3_overall={};
tic
cv_acc3={};
cv_acc3_trialLevel={};
for iter=4:5

    % split into training and testing trials, 15% test, 15% val, 70% test
    xx=1;xx1=1;xx2=1;yy=0;
    while xx<7 || xx1<7 || xx2<7
        test_idx = randperm(length(condn_data_overall),round(0.15*length(condn_data_overall)));
        test_idx=test_idx(:);
        I = ones(length(condn_data_overall),1);
        I(test_idx)=0;
        train_val_idx = find(I~=0);
        prop = (0.72/0.85);
        tmp_idx = randperm(length(train_val_idx),round(prop*length(train_val_idx)));
        train_idx = train_val_idx(tmp_idx);train_idx=train_idx(:);
        I = ones(length(condn_data_overall),1);
        I([train_idx;test_idx])=0;
        val_idx = find(I~=0);val_idx=val_idx(:);
        xx = length(unique([condn_data_overall(train_idx).targetID]));
        xx1 = length(unique([condn_data_overall(val_idx).targetID]));
        xx2 = length(unique([condn_data_overall(test_idx).targetID]));
        yy=yy+1;
    end

    % training options for NN
    [options,XTrain,YTrain] = ...
        get_options(condn_data_overall,val_idx,train_idx);

    % grid search
    %num_units = [32,64,96,128];
    num_units = [64,96,150,256];
    num_layers = [1,2,3];
    %cv_acc={};
    %cv_acc2={};
    i3=1;

    for i=1:length(num_layers)      
        if i==1
            % loop over number of units
            for j=1:length(num_units)
                disp(['Iteration ' num2str(iter) ' Arch idx ' num2str(i3)])
                % net = patternnet([num_units(j)]) ;
                % net.performParam.regularization=0.2;
                % net = train(net,N,T','useParallel','yes');
                % cv_acc{j} = cv_perf;
                aa=condn_data_overall(1).neural;
                s=size(aa,1);
                layers = get_layers1(num_units(j),s);
                net = trainNetwork(XTrain,YTrain,layers,options);
                cv_perf = test_network(net,condn_data_overall,test_idx);
                [conf_matrix] = test_network_trialLevel(net,condn_data_overall,test_idx);
                cv_perf_trialLevel = nanmean(diag(conf_matrix));
                if iter==1
                    cv_acc3(i3).cv_perf = cv_perf;
                    cv_acc3(i3).layers=[num_units(j),0,0];
                    cv_acc3_trialLevel(i3).cv_perf_trialLevel = cv_perf_trialLevel;
                    cv_acc3_trialLevel(i3).layers=[num_units(j),0,0];                    
                    i3=i3+1;
                else
                    cv_acc3(i3).cv_perf = [cv_acc3(i3).cv_perf cv_perf];
                    cv_acc3_trialLevel(i3).cv_perf_trialLevel = ...
                        [cv_acc3_trialLevel(i3).cv_perf_trialLevel cv_perf_trialLevel];                    
                    %cv_acc3(i3).layers=[num_units(j),0,0];
                    i3=i3+1;
                end

            end


        elseif i==2
            % loop over number of units
            for j=1:length(num_units)
                for k=1:length(num_units)
                    disp(['Iteration ' num2str(iter) ' Arch idx ' num2str(i3)])
                    %net = patternnet([num_units(j) num_units(k)]) ;
                    %net.performParam.regularization=0.2;
                    %net = train(net,N,T','useParallel','yes');
                    %cv_acc2{j,k} = cv_perf;
                    aa=condn_data_overall(1).neural;
                    s=size(aa,1);
                    layers = get_layers2(num_units(j),num_units(k),s);
                    net = trainNetwork(XTrain,YTrain,layers,options);
                    cv_perf = test_network(net,condn_data_overall,test_idx);
                    [conf_matrix] = test_network_trialLevel(net,condn_data_overall,test_idx);
                    cv_perf_trialLevel = mean(diag(conf_matrix));
                    if iter==1
                        cv_acc3(i3).cv_perf = cv_perf;
                        cv_acc3(i3).layers=[num_units(j),num_units(k),0];
                        cv_acc3_trialLevel(i3).cv_perf_trialLevel = cv_perf_trialLevel;
                        cv_acc3_trialLevel(i3).layers=[num_units(j),num_units(k),0];
                        i3=i3+1;
                    else
                        cv_acc3(i3).cv_perf = [cv_acc3(i3).cv_perf cv_perf];
                        cv_acc3_trialLevel(i3).cv_perf_trialLevel = ...
                            [cv_acc3_trialLevel(i3).cv_perf_trialLevel cv_perf_trialLevel];
                        %cv_acc3(i3).layers=[num_units(j),num_units(k),0];
                        i3=i3+1;
                    end

                end
            end

        elseif i==3
            % loop over number of units
            for j=1:length(num_units)
                for k=1:length(num_units)
                    for l=1:length(num_units)
                        disp(['Iteration ' num2str(iter) ' Arch idx ' num2str(i3)])
                        %net = patternnet([num_units(j) num_units(k) num_units(l)]) ;
                        %net.performParam.regularization=0.2;
                        %net = train(net,N,T','useParallel','yes');
                        aa=condn_data_overall(1).neural;
                        s=size(aa,1);
                        layers = get_layers(num_units(j),num_units(k),num_units(l),s);
                        net = trainNetwork(XTrain,YTrain,layers,options);
                        cv_perf = test_network(net,condn_data_overall,test_idx);
                        [conf_matrix] = test_network_trialLevel(net,condn_data_overall,test_idx);
                        cv_perf_trialLevel = mean(diag(conf_matrix));
                        if iter==1
                            cv_acc3(i3).cv_perf = cv_perf;
                            cv_acc3(i3).layers=[num_units(j),num_units(k),num_units(l)];
                            cv_acc3_trialLevel(i3).cv_perf_trialLevel = cv_perf_trialLevel;
                            cv_acc3_trialLevel(i3).layers=[num_units(j),num_units(k),num_units(l)];
                            i3=i3+1;
                        else
                            cv_acc3(i3).cv_perf = [cv_acc3(i3).cv_perf cv_perf];
                            cv_acc3_trialLevel(i3).cv_perf_trialLevel =...
                                [cv_acc3_trialLevel(i3).cv_perf_trialLevel cv_perf_trialLevel];
                            i3=i3+1;
                        end

                    end
                end
            end
        end
        save B3_MLP_NN_Param_Optim_V3 cv_acc3 cv_acc3_trialLevel -v7.3
    end    
end
save B3_MLP_NN_Param_Optim_V3 cv_acc3 cv_acc3_trialLevel -v7.3
toc

% 
% %cv_acc_overall={};
% %cv_acc2_overall={};
% %cv_acc3_overall={};
% cv_acc3={};
% for iter=1:5
% 
%     % split into training and testing trials, 15% test, 15% val, 70% test
%     test_idx = randperm(length(condn_data_overall),round(0.15*length(condn_data_overall)));
%     test_idx=test_idx(:);
%     I = ones(length(condn_data_overall),1);
%     I(test_idx)=0;
%     train_val_idx = find(I~=0);
%     prop = (0.7/0.85);
%     tmp_idx = randperm(length(train_val_idx),round(prop*length(train_val_idx)));
%     train_idx = train_val_idx(tmp_idx);train_idx=train_idx(:);
%     I = ones(length(condn_data_overall),1);
%     I([train_idx;test_idx])=0;
%     val_idx = find(I~=0);val_idx=val_idx(:);
% 
%     % training options for NN
%     [options,XTrain,YTrain] = ...
%         get_options(condn_data_overall,val_idx,train_idx);
% 
%     % grid search
%     num_units = [64,96,150,256];
%     num_layers = [1,2,3];
%     %cv_acc={};
%     %cv_acc2={};
%     i3=1;
% 
%     for i=1:length(num_layers)
%         if i==1
%             % loop over number of units
%             for j=1:length(num_units)
%                 % net = patternnet([num_units(j)]) ;
%                 % net.performParam.regularization=0.2;
%                 % net = train(net,N,T','useParallel','yes');
%                 % cv_acc{j} = cv_perf;
%                 aa=condn_data_overall(1).neural;
%                 s=size(aa,1);
%                 layers = get_layers1(num_units(j),s);
%                 net = trainNetwork(XTrain,YTrain,layers,options);
%                 cv_perf = test_network(net,condn_data_overall,test_idx);
%                 if iter==1
%                     cv_acc3(i3).cv_perf = cv_perf;
%                     cv_acc3(i3).layers=[num_units(j),0,0];
%                     i3=i3+1;
%                 else
%                     cv_acc3(i3).cv_perf = [cv_acc3(i3).cv_perf cv_perf];
%                     %cv_acc3(i3).layers=[num_units(j),0,0];
%                     i3=i3+1;
%                 end
% 
%             end
% 
% 
%         elseif i==2
%             % loop over number of units
%             for j=1:length(num_units)
%                 for k=1:length(num_units)
%                     %net = patternnet([num_units(j) num_units(k)]) ;
%                     %net.performParam.regularization=0.2;
%                     %net = train(net,N,T','useParallel','yes');
%                     %cv_acc2{j,k} = cv_perf;
%                     layers = get_layers2(num_units(j),num_units(k),759);
%                     net = trainNetwork(XTrain,YTrain,layers,options);
%                     cv_perf = test_network(net,condn_data_overall,test_idx);
%                     if iter==1
%                         cv_acc3(i3).cv_perf = cv_perf;
%                         cv_acc3(i3).layers=[num_units(j),num_units(k),0];
%                         i3=i3+1;
%                     else
%                         cv_acc3(i3).cv_perf = [cv_acc3(i3).cv_perf cv_perf];
%                         %cv_acc3(i3).layers=[num_units(j),num_units(k),0];
%                         i3=i3+1;
%                     end
% 
%                 end
%             end
% 
%         elseif i==3
%             % loop over number of units
%             for j=1:length(num_units)
%                 for k=1:length(num_units)
%                     for l=1:length(num_units)
%                         %net = patternnet([num_units(j) num_units(k) num_units(l)]) ;
%                         %net.performParam.regularization=0.2;
%                         %net = train(net,N,T','useParallel','yes');
%                         layers = get_layers(num_units(j),num_units(k),num_units(l),759);
%                         net = trainNetwork(XTrain,YTrain,layers,options);
%                         cv_perf = test_network(net,condn_data_overall,test_idx);
%                         if iter==1
%                             cv_acc3(i3).cv_perf = cv_perf;
%                             cv_acc3(i3).layers=[num_units(j),num_units(k),num_units(l)];
%                             i3=i3+1;
%                         else
%                             cv_acc3(i3).cv_perf = [cv_acc3(i3).cv_perf cv_perf];
%                             i3=i3+1;
%                         end
% 
%                     end
%                 end
%             end
%         end
%     end
%     save B3_MLP_NN_Param_Optim_V2 cv_acc3 -v7.3
% end


%% getting decoding accuracies for zero layer

cd('/media/reza/ResearchDrive/B3 Data for ERP Analysis')
i3=length(cv_acc3)+1;
%load B3_MLP_NN_Param_Optim_V3
cv_acc3(i3).layers=[0];
cv_acc3_trialLevel(i3).layers=[0];
for iter=1:10

    disp(['Iteration number ' num2str(iter)])

    % split into training and testing trials, 15% test, 15% val, 70% test
    xx=1;xx1=1;xx2=1;yy=0;
    while xx<7 || xx1<7 || xx2<7
        test_idx = randperm(length(condn_data_overall),round(0.15*length(condn_data_overall)));
        test_idx=test_idx(:);
        I = ones(length(condn_data_overall),1);
        I(test_idx)=0;
        train_val_idx = find(I~=0);
        prop = (0.72/0.85);
        tmp_idx = randperm(length(train_val_idx),round(prop*length(train_val_idx)));
        train_idx = train_val_idx(tmp_idx);train_idx=train_idx(:);
        I = ones(length(condn_data_overall),1);
        I([train_idx;test_idx])=0;
        val_idx = find(I~=0);val_idx=val_idx(:);
        xx = length(unique([condn_data_overall(train_idx).targetID]));
        xx1 = length(unique([condn_data_overall(val_idx).targetID]));
        xx2 = length(unique([condn_data_overall(test_idx).targetID]));
        yy=yy+1;
    end

    % training options for NN
    [options,XTrain,YTrain] = ...
        get_options(condn_data_overall,val_idx,train_idx);

    %train NN and get CV
    aa=condn_data_overall(1).neural;
    s=size(aa,1);
    layers = get_layers0(s);
    net = trainNetwork(XTrain,YTrain,layers,options);

    % get CV
    cv_perf = test_network(net,condn_data_overall,test_idx);
    cv_acc3(i3).cv_perf = [ cv_acc3(i3).cv_perf cv_perf];
    [conf_matrix] = test_network_trialLevel(net,condn_data_overall,test_idx);
    cv_perf_trialLevel = mean(diag(conf_matrix));
    cv_acc3_trialLevel(i3).cv_perf_trialLevel =...
        [cv_acc3_trialLevel(i3).cv_perf_trialLevel cv_perf_trialLevel];


end
save B3_MLP_NN_Param_Optim_V3 cv_acc3 cv_acc3_trialLevel -v7.3

%% PLOTTING RESULTS

clc;clear
root_path = 'F:\DATA\ecog data\ECoG BCI\GangulyServer\Multistate B3';
addpath(genpath('C:\Users\nikic\Documents\GitHub\ECoG_BCI_HighDim'))
cd(root_path)
addpath('C:\Users\nikic\Documents\MATLAB\DrosteEffect-BrewerMap-5b84f95')
addpath 'C:\Users\nikic\Documents\MATLAB'
%load B3_MLP_NN_Param_Optim_V2
load B3_MLP_NN_Param_Optim
% plotting just mean
acc=[];acc1=[];
for i=1:length(cv_acc3)
    acc(i) = max(cv_acc3(i).cv_perf);
end

[aa bb]=max(acc)

figure;boxplot(acc(1:4))
ylim([.8 .9])
figure;boxplot(acc(5:20))
ylim([.8 .9])
figure;boxplot(acc(21:end))
ylim([.8 .9])

tmp=NaN(64,3);
tmp(1:4,1) = acc(1:4)';
tmp(1:16,2) = acc(5:20)';
tmp(1:end,3) = acc(21:end)';
figure;boxplot(tmp)

% plotting across all iterations to compare all layers
acc1=[];
for i=1:4
    acc1=[acc1;cv_acc3_trialLevel(i).cv_perf_trialLevel'];
end

acc2=[];
for i=5:20
    acc2=[acc2;cv_acc3_trialLevel(i).cv_perf_trialLevel'];
end

acc3=[];
for i=21:84
    acc3=[acc3;cv_acc3_trialLevel(i).cv_perf_trialLevel'];
end

acc0=cv_acc3_trialLevel(end).cv_perf_trialLevel';

acc0(end+1:length(acc3))=NaN;
acc1(end+1:length(acc3))=NaN;
acc2(end+1:length(acc3))=NaN;
acc=[acc0 acc1 acc2 acc3];
figure;
boxplot(acc,'notch','off')
set(gcf,'Color','w')
set(gca,'FontSize',12)
ylabel('Bin Level Decoding Acc')
xticks(1:4)
xticklabels({'0 Layers','1 Layer','2 Layer','3 Layer'})
box off
title('Cross. Valid for MLP width in B3')


% sign rank tests
clear p
[p(1),h,stats] = ranksum(acc0(~isnan(acc0)),acc1(~isnan(acc1)))
[p(2),h,stats] = ranksum(acc0(~isnan(acc0)),acc2(~isnan(acc2)))
[p(3),h,stats] = ranksum(acc0(~isnan(acc0)),acc3(~isnan(acc3)))
[p(4),h,stats] = ranksum(acc1(~isnan(acc1)),acc2(~isnan(acc2)))
[p(5),h,stats] = ranksum(acc1(~isnan(acc1)),acc3(~isnan(acc3)))
[p(6),h,stats] = ranksum(acc2(~isnan(acc2)),acc3(~isnan(acc3)))
[pfdr,pval]=fdr(p,0.05);pval

% testing comparison of units in single layer
acc_128=[];
for i=1:5
    layers = get_layers1(128,759);
    net = trainNetwork(XTrain,YTrain,layers,options);
    cv_perf = test_network(net,condn_data_overall,test_idx);
    acc_128(i)  = cv_perf;
end


acc_150=[];
for i=1:5
    layers = get_layers1(150,759);
    net = trainNetwork(XTrain,YTrain,layers,options);
    cv_perf = test_network(net,condn_data_overall,test_idx);
    acc_150(i)  = cv_perf;
end


%% having identified the fact that 1 layer is good, now going after the
% number of units, in steps of 10 from 100 to 250
num_units = [32 64 90:15:250];
cv_singleLayer={};
cv_singleLayer_trialLevel={};
for iter=1:10

    % split into training and testing trials, 15% test, 15% val, 70% test
    xx=1;xx1=1;xx2=1;yy=0;
    while xx<7 || xx1<7 || xx2<7
        test_idx = randperm(length(condn_data_overall),round(0.15*length(condn_data_overall)));
        test_idx=test_idx(:);
        I = ones(length(condn_data_overall),1);
        I(test_idx)=0;
        train_val_idx = find(I~=0);
        prop = (0.72/0.85);
        tmp_idx = randperm(length(train_val_idx),round(prop*length(train_val_idx)));
        train_idx = train_val_idx(tmp_idx);train_idx=train_idx(:);
        I = ones(length(condn_data_overall),1);
        I([train_idx;test_idx])=0;
        val_idx = find(I~=0);val_idx=val_idx(:);
        xx = length(unique([condn_data_overall(train_idx).targetID]));
        xx1 = length(unique([condn_data_overall(val_idx).targetID]));
        xx2 = length(unique([condn_data_overall(test_idx).targetID]));
        yy=yy+1;
    end
   

    % training options for NN
    [options,XTrain,YTrain] = ...
        get_options(condn_data_overall,val_idx,train_idx);
    i3=1;

    for j=1:length(num_units)
        layers = get_layers1(num_units(j),759);
        disp(['Iteration: ' num2str(iter) ' & No. Units: ' num2str(num_units(j))])
        net = trainNetwork(XTrain,YTrain,layers,options);
        cv_perf = test_network(net,condn_data_overall,test_idx);
        [conf_matrix] = test_network_trialLevel(net,condn_data_overall,test_idx);
        cv_perf_trialLevel = mean(diag(conf_matrix));
        if iter==1
            cv_singleLayer(i3).cv_perf = cv_perf;
            cv_singleLayer(i3).layers=[num_units(j),0,0];
            cv_singleLayer_trialLevel(i3).cv_perf_trialLevel = cv_perf_trialLevel;
            cv_singleLayer_trialLevel(i3).layers=[num_units(j),0,0];
            i3=i3+1;
        else
            cv_singleLayer(i3).cv_perf = [cv_singleLayer(i3).cv_perf cv_perf];            
            cv_singleLayer_trialLevel(i3).cv_perf_trialLevel =...
                [cv_singleLayer_trialLevel(i3).cv_perf_trialLevel cv_perf_trialLevel];
            %cv_acc3(i3).layers=[num_units(j),0,0];
            i3=i3+1;
        end
    end
end

save B3_MLP_NN_Param_Optim_V3_singleLayer cv_singleLayer_trialLevel

num_units = [32 64 90:15:250];
acc=[];acc1=[];
for i=1:length(cv_singleLayer)
    tmp = cv_singleLayer(i).cv_perf;
    acc(:,i) = tmp';
    acc1(i) = mean(tmp);
end
figure;boxplot(acc)
set(gcf,'Color','w')
set(gca,'FontSize',12)
ylabel('Bin Level Decoding Acc')
xticks(1:size(acc,2))
xticklabels((num_units))
box off
title('Cross. Valid for num units in 1 Layer MLP')
xlabel('Number of units')
hold on
plot(mean(acc,1),'--k','LineWidth',1)


[aa bb]=max(acc1)

figure;bar(acc1)
xticks(1:size(acc,2))
xticklabels((num_units))
ylim([0.83 0.87])

accb=(bootstrp(1000,@mean,acc));
figure;boxplot(accb)
set(gcf,'Color','w')
set(gca,'FontSize',12)
ylabel('Bin Level Decoding Acc')
xticks(1:size(acc,2))
xticklabels((num_units))
box off
title('Cross. Valid for num units in 1 Layer MLP')
xlabel('Number of units')

save B3_MLP_NN_SingleLayer_UnitsOptim cv_singleLayer -v7.3

%% GRID SEARCH TO CHECK FOR PNP

%% STEP 1 Load all the historical data
clc;clear
root_path = 'F:\DATA\ecog data\ECoG BCI\GangulyServer\Multistate B3';
addpath(genpath('C:\Users\nikic\Documents\GitHub\ECoG_BCI_HighDim'))
cd(root_path)
addpath('C:\Users\nikic\Documents\MATLAB\DrosteEffect-BrewerMap-5b84f95')
load session_data_B3
addpath 'C:\Users\nikic\Documents\MATLAB'
load('ECOG_Grid_8596_000067_B3.mat')
condn_data={};
for i=1:11%all the original data without covert mime
    folders_imag =  strcmp(session_data(i).folder_type,'I');
    folders_online = strcmp(session_data(i).folder_type,'O');
    folders_batch = strcmp(session_data(i).folder_type,'B');

    imag_idx = find(folders_imag==1);
    online_idx = find(folders_online==1);
    batch_idx = find(folders_batch==1);


    %%%%%% load imagined data
    folders = session_data(i).folders(imag_idx);
    day_date = session_data(i).Day;
    files=[];
    for ii=1:length(folders)
        folderpath = fullfile(root_path, day_date,'Robot3DArrow',folders{ii},'Imagined');
        %cd(folderpath)
        files = [files;findfiles('',folderpath)'];
    end
    condn_data = [condn_data;load_data_for_MLP_TrialLevel_B3(files,ecog_grid,0,0)];

    %%%%%% load online data
    folders = session_data(i).folders(online_idx);
    day_date = session_data(i).Day;
    files=[];
    for ii=1:length(folders)
        folderpath = fullfile(root_path, day_date,'Robot3DArrow',folders{ii},'BCI_Fixed');
        %cd(folderpath)
        files = [files;findfiles('',folderpath)'];
    end
    condn_data = [condn_data;load_data_for_MLP_TrialLevel_B3(files,ecog_grid,1,0) ];

    %%%%%% load batch data
    folders = session_data(i).folders(batch_idx);
    day_date = session_data(i).Day;
    files=[];
    for ii=1:length(folders)
        folderpath = fullfile(root_path, day_date,'Robot3DArrow',folders{ii},'BCI_Fixed');
        %cd(folderpath)
        files = [files;findfiles('',folderpath)'];
    end
    condn_data = [condn_data;load_data_for_MLP_TrialLevel_B3(files,ecog_grid,2,0) ];
end

% make them all into one giant struct
tmp=cell2mat(condn_data(1));
condn_data_overall=tmp;
for i=2:length(condn_data)
    tmp=cell2mat(condn_data(i));
    for k=1:length(tmp)
        condn_data_overall(end+1) =tmp(k);
    end
end

condn_data_overall_first11=condn_data_overall;



% split the data into validation and training sets
test_idx = randperm(length(condn_data_overall_first11),...
    round(0.2*length(condn_data_overall_first11)));
test_idx=test_idx(:);
I = ones(length(condn_data_overall_first11),1);
I(test_idx)=0;
train_idx = find(I~=0);train_idx=train_idx(:);

% training options for NN MLP
[optionsA,XTrainA,YTrainA] = ...
    get_options(condn_data_overall_first11,test_idx,train_idx);
optionsA.Plots='none';
disp('STEP 1 DONE')
status_check='step 1 done';

%% STEP 2 Load all the new data
condn_data={};
load('ECOG_Grid_8596_000067_B3.mat')
for i=12:19 %- all the original data without covert mime, 23 -> includes PnP data
    folders_imag =  strcmp(session_data(i).folder_type,'I');
    folders_online = strcmp(session_data(i).folder_type,'O');
    folders_batch = strcmp(session_data(i).folder_type,'B');

    imag_idx = find(folders_imag==1);
    online_idx = find(folders_online==1);
    batch_idx = find(folders_batch==1);


    %%%%% load imagined data
    folders = session_data(i).folders(imag_idx);
    day_date = session_data(i).Day;
    files=[];
    for ii=1:length(folders)
        folderpath = fullfile(root_path, day_date,'Robot3DArrow',folders{ii},'Imagined');
        %cd(folderpath)
        files = [files;findfiles('',folderpath)'];
    end
    condn_data = [condn_data;load_data_for_MLP_TrialLevel_B3(files,ecog_grid,0,0)];

    %%%%%% load online data
    folders = session_data(i).folders(online_idx);
    day_date = session_data(i).Day;
    files=[];
    for ii=1:length(folders)
        folderpath = fullfile(root_path, day_date,'Robot3DArrow',folders{ii},'BCI_Fixed');
        %cd(folderpath)
        files = [files;findfiles('',folderpath)'];
    end
    condn_data = [condn_data;load_data_for_MLP_TrialLevel_B3(files,ecog_grid,1,0) ];

    %%%%%% load batch data
    folders = session_data(i).folders(batch_idx);
    day_date = session_data(i).Day;
    files=[];
    for ii=1:length(folders)
        folderpath = fullfile(root_path, day_date,'Robot3DArrow',folders{ii},'BCI_Fixed');
        %cd(folderpath)
        files = [files;findfiles('',folderpath)'];
    end
    condn_data = [condn_data;load_data_for_MLP_TrialLevel_B3(files,ecog_grid,2,0) ];
end

% make them all into one giant struct
tmp=cell2mat(condn_data(1));
condn_data_overall=tmp;
for i=2:length(condn_data)
    tmp=cell2mat(condn_data(i));
    for k=1:length(tmp)
        condn_data_overall(end+1) =tmp(k);
    end
end

condn_data_overall_11thru19 = condn_data_overall;

% split the data into validation and training sets
test_idx = randperm(length(condn_data_overall_11thru19),...
    round(0.2*length(condn_data_overall_11thru19)));
test_idx=test_idx(:);
I = ones(length(condn_data_overall_11thru19),1);
I(test_idx)=0;
train_idx = find(I~=0);train_idx=train_idx(:);

% training options for NN MLP
[optionsB,XTrainB,YTrainB] = ...
    get_options(condn_data_overall_11thru19,test_idx,train_idx,7.5e-4);
optionsB.Plots='none';

disp('STEP 2 DONE')
status_check='step 2 done';

%% STEP 3: GET THE DATA FROM THE PNP DAY

condn_data={};
load('ECOG_Grid_8596_000067_B3.mat')
i=20;%all the original data without covert mime
folders_imag =  strcmp(session_data(i).folder_type,'I');
folders_online = strcmp(session_data(i).folder_type,'O');
folders_batch = strcmp(session_data(i).folder_type,'B');

imag_idx = find(folders_imag==1);
online_idx = find(folders_online==1);
batch_idx = find(folders_batch==1);

%%%%%% load batch data
folders = session_data(i).folders(batch_idx);
day_date = session_data(i).Day;
files=[];
for ii=1:length(folders)
    folderpath = fullfile(root_path, day_date,'Robot3DArrow',folders{ii},'BCI_Fixed');
    %cd(folderpath)
    files = [files;findfiles('',folderpath)'];
end
condn_data = [condn_data;load_data_for_MLP_TrialLevel_B3(files,ecog_grid,2,0) ];
[acc_batch_trial,acc_batch] = accuracy_online_data(files);
pnp_perf=mean([diag(acc_batch)]);

% make them all into one giant struct
tmp=cell2mat(condn_data(1));
condn_data_overall=tmp;
for i=2:length(condn_data)
    tmp=cell2mat(condn_data(i));
    for k=1:length(tmp)
        condn_data_overall(end+1) =tmp(k);
    end
end

condn_data_overall_test=condn_data_overall;

disp('STEP 3 DONE')
status_check='step 3 done';


%% STEP 4 CHECK DECODING PERFORMANCE FOR DIFFERENT LAYER SIZES
tic
cv_acc3={};
num_units = [64,120,256];
num_layers = [1,2,3];
for iter=1:1
    i3=1;
    for i=1:length(num_layers)
        if i==1
            % loop over number of units
            for j=1:length(num_units)






                % pass it through an autoencoder
                layers_ae = get_layers_AE(300,150,759);
                optionsAE = optionsA;
                optionsAE.ValidationData{2}=optionsAE.ValidationData{1};
                optionsAE.Plots='training-progress';
                ae = trainNetwork(XTrainA,XTrainA,layers_ae,optionsAE);

                XTrainA=predict(ae,XTrainA);

                clear net layers
                a=condn_data_overall(1).neural;
                s=size(a,1);
                layers = get_layers1(num_units(j),s);
                %layers = get_layers2(120,64,759);
                %layers = get_layers(120,64,64,759);
                % train
                net = trainNetwork(XTrainA,YTrainA,layers,optionsA);
                % batch update
                net = trainNetwork(XTrainB,YTrainB,net.Layers,optionsB);
                % test network
                test_idx=1:length(condn_data_overall_test);
                [cv_perf,conf_matrix] = ...
                    test_network(net,condn_data_overall_test,test_idx);


                if iter==1
                    cv_acc3(i3).cv_perf = cv_perf;
                    cv_acc3(i3).layers=[num_units(j),0,0];
                    cv_acc3(i3).net=net;
                    i3=i3+1;
                else
                    cv_acc3(i3).cv_perf = [cv_acc3(i3).cv_perf cv_perf];
                    %cv_acc3(i3).layers=[num_units(j),0,0];
                    i3=i3+1;
                end

            end


        elseif i==2
            % loop over number of units
            for j=1:length(num_units)
                for k=1:length(num_units)




                    clear net layers
                    layers = get_layers2(num_units(j),num_units(k),759);
                    % train
                    net = trainNetwork(XTrainA,YTrainA,layers,optionsA);
                    % batch update
                    net = trainNetwork(XTrainB,YTrainB,net.Layers,optionsB);
                    % test network
                    test_idx=1:length(condn_data_overall_test);
                    [cv_perf,conf_matrix] = ...
                        test_network(net,condn_data_overall_test,test_idx);

                    if iter==1
                        cv_acc3(i3).cv_perf = cv_perf;
                        cv_acc3(i3).layers=[num_units(j),num_units(k),0];
                        cv_acc3(i3).net=net;
                        i3=i3+1;
                    else
                        cv_acc3(i3).cv_perf = [cv_acc3(i3).cv_perf cv_perf];
                        %cv_acc3(i3).layers=[num_units(j),num_units(k),0];
                        i3=i3+1;
                    end

                end
            end

        elseif i==3
            % loop over number of units
            for j=1:length(num_units)
                for k=1:length(num_units)
                    for l=1:length(num_units)

                        clear net layers
                        layers = get_layers(num_units(j),num_units(k),num_units(l),759);
                        % train
                        net = trainNetwork(XTrainA,YTrainA,layers,optionsA);
                        % batch update
                        net = trainNetwork(XTrainB,YTrainB,net.Layers,optionsB);
                        % test network
                        test_idx=1:length(condn_data_overall_test);
                        [cv_perf,conf_matrix] = ...
                            test_network(net,condn_data_overall_test,test_idx);
                        if iter==1
                            cv_acc3(i3).cv_perf = cv_perf;
                            cv_acc3(i3).layers=[num_units(j),num_units(k),num_units(l)];
                            cv_acc3(i3).net=net;
                            i3=i3+1;
                        else
                            cv_acc3(i3).cv_perf = [cv_acc3(i3).cv_perf cv_perf];
                            i3=i3+1;
                        end

                    end
                end
            end
        end
    end

end
toc

% zeroth layer
i3=length(cv_acc3)+1;
cv_acc3(i3).layers=[0];
for iter=1:2

    clear net layers
    layers = get_layers0(759);
    % train
    net = trainNetwork(XTrainA,YTrainA,layers,optionsA);
    % batch update
    net = trainNetwork(XTrainB,YTrainB,net.Layers,optionsB);
    % test network
    test_idx=1:length(condn_data_overall_test);
    [cv_perf,conf_matrix] = ...
        test_network(net,condn_data_overall_test,test_idx);
    cv_acc3(i3).cv_perf = [ cv_acc3(i3).cv_perf cv_perf];
end


% plotting across all iterations to compare all layers
acc1=[];
for i=1:3
    acc1=[acc1;cv_acc3(i).cv_perf'];
end

acc2=[];
for i=4:12
    acc2=[acc2;cv_acc3(i).cv_perf'];
end

acc3=[];
for i=13:39
    acc3=[acc3;cv_acc3(i).cv_perf'];
end

acc0=cv_acc3(end).cv_perf';

acc0(end+1:length(acc3))=NaN;
acc1(end+1:length(acc3))=NaN;
acc2(end+1:length(acc3))=NaN;
acc=[acc0 acc1 acc2 acc3];
figure;
boxplot(acc,'notch','off')
set(gcf,'Color','w')
set(gca,'FontSize',12)
ylabel('Bin Level Decoding Acc')
xticks(1:4)
xticklabels({'0 Layers','1 Layer','2 Layer','3 Layer'})
box off
title('Cross. Valid for MLP width in B3')

% plotting just mean
acc=[];acc1=[];
for i=1:length(cv_acc3)
    acc(i) = mean(cv_acc3(i).cv_perf);
end

[aa bb]=max(acc)

%% COMPARISON OF POOLING AND NO POOLING ONLINE FOR B3 DATA

clc;clear;
close all
root_path='F:\DATA\ecog data\ECoG BCI\GangulyServer\Multistate B3\20230216\';

folders={'122733','123155'}; % pooling
%folders={'123740','124104'};%no pooling

files=[];
for i=1:length(folders)
    filepath=fullfile(root_path,'RadialTaskMultiStateDiscreteArrow',folders{i},'BCI_Fixed');
    files=[files;findfiles('',filepath)'];
end

decodes=[];
num_targets=4;
trial_acc=zeros(num_targets);
for i=1:length(files)
    disp(i/length(files)*100)
    load(files{i});
    tid=TrialData.TargetID;
    out=TrialData.ClickerState;
    decodes_vote=[];
    for i=1:(num_targets)
        decodes_vote(i)=sum(out==i);
    end
    [aa bb]=max(decodes_vote);
    trial_acc(tid,bb)=trial_acc(tid,bb)+1;
    idx=(out==tid);
    idx1=(out~=tid);
    out(idx)=1;
    out(idx1)=0;
    decodes=[decodes out];
end

for i=1:length(trial_acc)
    trial_acc(i,:)=trial_acc(i,:)/sum(trial_acc(i,:));
end

diag(trial_acc)
mean(diag(trial_acc))
mean(decodes)

TrialData.Params.ChPooling

